{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fcb85e5-b780-4187-8feb-54f67645c9ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Fine-Tuning a Transformer Model on Azure Databricks\n",
    "\n",
    "## Overview\n",
    "This notebook guides you through the process of preparing data and executing the fine-tuning of a transformer model using Azure Databricks.\n",
    "\n",
    "## Objectives\n",
    "- Setup the environments\n",
    "- Load datasets \n",
    "- Configure and train a transformer model.\n",
    "- Evaluate model performance and save results.\n",
    "\n",
    "\n",
    "## Author\n",
    "- Name: Alessandro Armillotta\n",
    "- Date: 09/10/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97551e36-1d8a-4b90-a38f-b1ccfadfdae2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Steps\n",
    "1. Data loading and preprocessing.\n",
    "2. Model configuration and fine-tuning.\n",
    "3. Model evaluation and saving.\n",
    "4. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c3feba1-a8a0-426f-b150-fb259a74258b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Widgets"
    }
   },
   "outputs": [],
   "source": [
    "# Create Databricks widgets to make the notebook configurable.\n",
    "# 'experiment_name' will be used to define the MLflow experiment where training runs are logged.\n",
    "# 'base_model' defines which pretrained model from Hugging Face will be used as the starting point.\n",
    "dbutils.widgets.text(\"experiment_name\", \"fine_tuning_transformer_model\")\n",
    "dbutils.widgets.text(\"base_model\", \"google-bert/bert-base-uncased\")\n",
    "dbutils.widgets.text(\"run_name\", \"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4daadbf-1461-4426-b1ca-700bc7176122",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read Widgets"
    }
   },
   "outputs": [],
   "source": [
    "# Read the values provided through the Databricks widgets.\n",
    "# These variables can now be used throughout the notebook for dynamic configuration.\n",
    "experiment_name = dbutils.widgets.get(\"experiment_name\")\n",
    "base_model      = dbutils.widgets.get(\"base_model\")\n",
    "run_name        = dbutils.widgets.get(\"run_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f82ca560-2772-42e9-9d21-f5f451ea2234",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 0: Setup Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2caa09d8-fadd-4d17-a46b-f48af2c1ee99",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import Libraries"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Import Hugging Face and PyTorch core components\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, pipeline, EarlyStoppingCallback\n",
    "from pyspark.sql import functions as F\n",
    "import datasets\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "\n",
    "# Import MLflow for experiment tracking and model logging\n",
    "import mlflow\n",
    "mlflow.set_registry_uri(\"databricks-uc\") # Use Unity Catalog as MLflow model registry\n",
    "mlflow.set_tracking_uri(\"databricks\") # Enable experiment tracking in Databricks\n",
    "\n",
    "# Logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# GPU/CPU Setup\n",
    "# Automatically detect whether a GPU is available and configure CUDA environment variables.\n",
    "# If no GPU is detected, training will fall back to CPU.\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = \"cuda\" if USE_CUDA else \"cpu\"\n",
    "\n",
    "print(f\"üî• Device in uso: {DEVICE}\")\n",
    "if USE_CUDA:\n",
    "    print(f\"GPU rilevata: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nessuna GPU rilevata ‚Äî training su CPU\")\n",
    "\n",
    "# Disable parallel tokenizers warnings to prevent multiprocessing deadlocks\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Configure visible CUDA devices if GPU is available\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" if USE_CUDA else \"\"\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "\n",
    "# Only check BF16 support if CUDA is available\n",
    "USE_BF16 = torch.cuda.is_bf16_supported() if USE_CUDA else False\n",
    "USE_FP16 = USE_CUDA and not USE_BF16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cc584d7-a53b-4004-a93f-19c51ee66f88",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define Variables"
    }
   },
   "outputs": [],
   "source": [
    "experiment_name = f'/{experiment_name}'\n",
    "\n",
    "train_cache_dir   = \"/Volumes/main/fine_tuning_transformer_model/tmp/train\"\n",
    "val_cache_dir     = \"/Volumes/main/fine_tuning_transformer_model/tmp/val\"\n",
    "\n",
    "\n",
    "model_output_dir    = \"/Volumes/main/fine_tuning_transformer_model/tmp/output_model\"\n",
    "model_artifact_path = \"classification\"\n",
    "training_output_dir = \"/Volumes/main/fine_tuning_transformer_model/tmp/trainer\"\n",
    "pipeline_output_dir = \"/Volumes/main/fine_tuning_transformer_model/tmp/pipeline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84456717-21ba-49c8-a0f3-716f4f6fc3ac",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set Experiment"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    \n",
    "    if experiment is None:\n",
    "        experiment_id = mlflow.create_experiment(\n",
    "            name=experiment_name,\n",
    "            tags={'exp_name': experiment_name}\n",
    "        )\n",
    "        mlflow.set_experiment(experiment_id=experiment_id)\n",
    "        print(f\"Experiment {experiment_name} created.\")\n",
    "    else:\n",
    "        mlflow.set_experiment(experiment_id=experiment.experiment_id)\n",
    "        print(f\"Experiment {experiment_name} already exists.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b7e3ccf-75ac-49e7-948e-a4204d8db832",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 1: Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e5c74fd-0143-4ae9-9059-0e89042e4a0b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read Delta Tables"
    }
   },
   "outputs": [],
   "source": [
    "# load delta tables into dataframe\n",
    "train_df = spark.read.table(\"main.fine_tuning_transformer_model.train_data\")\n",
    "print(train_df.count())\n",
    "\n",
    "test_df   = spark.read.table(\"main.fine_tuning_transformer_model.test_data\")\n",
    "print(test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "164d42e0-e66e-4f00-89e0-d8e351b72178",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define Labels"
    }
   },
   "outputs": [],
   "source": [
    "labels = spark.read.table(\"main.fine_tuning_transformer_model.labels\")\n",
    "labels = labels.collect()\n",
    "\n",
    "id2label = {index: row.label for (index, row) in enumerate(labels)}\n",
    "label2id = {row.label: index for (index, row) in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7036ae2f-59a0-4c40-a4d5-445d824d86af",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Spark Dataframe to Transformer Dataset"
    }
   },
   "outputs": [],
   "source": [
    "# create a label with id if you don't have it as id. This is needed especially for text labels\n",
    "#train_dataset = train_df.select(\"text\",\"label_id\").withColumn(\"label\", F.col(\"label_id\")).drop(\"label_id\")\n",
    "#test_dataset   = val_df.select(\"text\",\"label_id\").withColumn(\"label\", F.col(\"label_id\")).drop(\"label_id\")\n",
    "\n",
    "# if you use a serverless compute\n",
    "#train_df = train_df.toPandas()\n",
    "#test_df = test_df.toPandas()\n",
    "#train_dataset = datasets.Dataset.from_pandas(train_df)\n",
    "#test_dataset   = datasets.Dataset.from_pandas(test_df)\n",
    "\n",
    "# if you use a non serverless compute\n",
    "train_dataset = datasets.Dataset.from_spark(train_df, cache_dir=train_cache_dir)\n",
    "test_dataset  = datasets.Dataset.from_spark(test_df, cache_dir=val_cache_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed982c29-90ec-4aca-bfb9-8360bc4bf5fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 2: Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "676e6a83-668c-4f4d-abb0-d42b6542cbdb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Tokenizer"
    }
   },
   "outputs": [],
   "source": [
    "# Load Tokenizer baseed on the Model Name. Transformers models expect tokenized input\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"],truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "train_tokenized  = train_dataset.map(tokenize_function, batched=True)\n",
    "test_tokenized   = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf27b992-37e9-491d-b750-599d200e0ead",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "AutoModel for Text Classification"
    }
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        base_model,\n",
    "        num_labels=len(label2id),\n",
    "        label2id=label2id,\n",
    "        id2label=id2label\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4e80542-64a1-44b2-b76c-e421f2ab4792",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Training arguments refer to a set of hyperparameters that control how a model is trained. These are passed to the TrainingArguments class and used by the Trainer API to manage the training loop. [huggingface.co]\n",
    "\n",
    "Think of training arguments as the recipe for model training: each parameter influences how the model learns, how fast it converges, and how well it generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b622d46e-36a6-4320-875c-fdc2fdd2cc8f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Training Arguments"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=training_output_dir,\n",
    "    per_device_train_batch_size=64 if USE_CUDA else 32,\n",
    "    per_device_eval_batch_size=64 if USE_CUDA else 32,\n",
    "    do_eval=True,\n",
    "    do_train=True,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=2e-5,\n",
    "    optim=\"adamw_torch\",\n",
    "    fp16=USE_CUDA,\n",
    "    bf16=False,\n",
    "    max_grad_norm=1.0,\n",
    "\n",
    "    dataloader_num_workers=8 if USE_CUDA else 0,\n",
    "    dataloader_pin_memory=USE_CUDA,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    #eval_steps=10, # only if eval_strategy is step\n",
    "    #save_steps=10, # only if save_strategy is step\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_accuracy\",\n",
    "    greater_is_better=True,\n",
    "    logging_steps=2,\n",
    "    report_to=\"mlflow\",\n",
    "\n",
    "    no_cuda=not USE_CUDA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bded42e4-bc61-46c6-9e73-e8b64839e30e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Data Collator"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b061366-fd21-4b7d-af8a-e4ea4813e83f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Metrics"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\"accuracy\": accuracy_score(labels, predictions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "015ec242-0a5a-42d3-b2d2-745b1da3c1a2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define Trainer"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c495e8f-99c2-42d1-95e1-ef10ba239d57",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Start Training"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  with mlflow.start_run(experiment_id=experiment.experiment_id, run_name=f\"trainer_{run_name}\") as run:\n",
    "    trainer.train()\n",
    "    trainer.save_model(model_output_dir)\n",
    "\n",
    "    pipe = pipeline(\"text-classification\", model=AutoModelForSequenceClassification.from_pretrained(model_output_dir), batch_size=1, tokenizer=tokenizer)\n",
    "\n",
    "    pipe.save_pretrained(pipeline_output_dir)\n",
    "\n",
    "    model_info = mlflow.transformers.log_model(\n",
    "                                              transformers_model=pipe,\n",
    "                                              artifact_path=model_artifact_path,\n",
    "                                              input_example=\"Hi there!\")\n",
    "    \n",
    "    mlflow.end_run()\n",
    "  \n",
    "  \n",
    "except Exception as e:\n",
    "  print(f\"An error occurred: {e}\")\n",
    "  mlflow.end_run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb76278b-1f97-4693-8392-704ba03fd290",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 4: Load Logged Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0a08101-65c2-4ad8-8dbe-17dda6d1200e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load model"
    }
   },
   "outputs": [],
   "source": [
    "logged_model = f\"runs:/{run.info.run_id}/{model_artifact_path}\"\n",
    "model = mlflow.pyfunc.spark_udf(spark, model_uri=logged_model, result_type='string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "682133ae-17c3-410c-885b-0986a92468ff",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Apply model on data"
    }
   },
   "outputs": [],
   "source": [
    "test = test_df.select(test_df.text, test_df.label, model(test_df.text).alias(\"prediction\"))\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73c08a72-c92d-4de0-9137-2b76d6872f1c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save Prediction"
    }
   },
   "outputs": [],
   "source": [
    "test.write.mode(\"overwrite\").saveAsTable(\"main.fine_tuning_transformer_model.prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a50e0de8-130c-4ea7-a7fe-aac90846ad99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b674778-f490-41a1-afb5-9a02ccdd5e67",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Register Model"
    }
   },
   "outputs": [],
   "source": [
    "mv = mlflow.register_model(logged_model, \"main.fine_tuning_transformer_model.classification_model\")\n",
    "print(f\"Name: {mv.name}\")\n",
    "print(f\"Version: {mv.version}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": "A10",
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "-r /Workspace/Users/alessandro.armillotta@mitavanadeitaly.onmicrosoft.com/Fine-Tuning-with-Databricks/requirements.txt"
    ],
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02.fine_tuning_with_trainer",
   "widgets": {
    "base_model": {
     "currentValue": "google-bert/bert-base-uncased",
     "nuid": "380bef05-da6e-4800-81bd-833b4e48320d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "google-bert/bert-base-uncased",
      "label": null,
      "name": "base_model",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "google-bert/bert-base-uncased",
      "label": null,
      "name": "base_model",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "experiment_name": {
     "currentValue": "fine_tuning_model",
     "nuid": "27144b6f-8ea1-4ded-9d30-4eea3e40e214",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "fine_tuning_transformer_model",
      "label": null,
      "name": "experiment_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "fine_tuning_transformer_model",
      "label": null,
      "name": "experiment_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "run_name": {
     "currentValue": "google-bert/bert-base-uncased",
     "nuid": "6dc7cf9b-be92-4c1d-b882-a18721b6adbb",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "google-bert/bert-base-uncased",
      "label": null,
      "name": "run_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "google-bert/bert-base-uncased",
      "label": null,
      "name": "run_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
